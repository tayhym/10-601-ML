\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}SVM (40 points)}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The Dataset}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Training SVM}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Kernel Function}{1}}
\@writefile{toc}{\contentsline {paragraph}{(20 points) Implement the kernel functions.}{1}}
\@writefile{toc}{\contentsline {paragraph}{(20 points) Question}{1}}
\newlabel{bananaset}{{1.2.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SVM decision boundary with different slackness and kernel.}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Compare Classifiers (60 points)}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Implement the Neural Network}{2}}
\newlabel{bananaset}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Banana dataset. Created from two intertwined banana shaped distributions. Red is class 1 and blue is class 0. It is not possible to classify this dataset well using a 2D linear classifier.}}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Training}{2}}
\@writefile{toc}{\contentsline {paragraph}{Forward propagation}{2}}
\citation{ngsparseae}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Schematic of a Feedforward Neural Network used for the Banana Dataset.}}{3}}
\newlabel{exampleNN}{{3}{3}}
\@writefile{toc}{\contentsline {paragraph}{Backpropagation}{3}}
\@writefile{toc}{\contentsline {paragraph}{Putting it together}{3}}
\@writefile{toc}{\contentsline {paragraph}{(45 points) Implement the function \texttt  {J} in \texttt  {./NN/J.m} using the above algorithm.}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Testing}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Three neural networks with different numbers of hidden units and different $\lambda $ settings and the effect on learning.}}{4}}
\newlabel{overfitting}{{4}{4}}
\@writefile{toc}{\contentsline {paragraph}{(5 points) Implement the function \texttt  {nnComputeActivations}.}{4}}
\@writefile{toc}{\contentsline {paragraph}{(0 points) Run \texttt  {runNNClassification}.}{4}}
\@writefile{toc}{\contentsline {paragraph}{Model Selection}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Applying the Neural Network to Classifying MNIST}{4}}
\@writefile{toc}{\contentsline {paragraph}{(5 points) Implement the function \texttt  {nnPredictClassification}.}{4}}
\@writefile{toc}{\contentsline {paragraph}{(0 points) Run \texttt  {runDigits.m}}{4}}
\@writefile{toc}{\contentsline {paragraph}{Weights}{4}}
\citation{Tibshirani94regressionshrinkage}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualizing the weights $W_1$ from the input layer to the hidden layer on a neural network with 100 hidden units. Running \texttt  {digits.m} should generate a similar set of weights.}}{5}}
\newlabel{weights}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Neural Network Regression}{5}}
\@writefile{toc}{\contentsline {paragraph}{Changes to the cost and gradient.}{5}}
\@writefile{toc}{\contentsline {paragraph}{(5 points) Modify \texttt  {J.m} to implement regression.}{5}}
\@writefile{toc}{\contentsline {paragraph}{(0 points) Run \texttt  {runNNRegression.m}.}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Extra Credit}{5}}
\citation{DBLP:journals/corr/abs-1207-0580}
\bibdata{hw3_writeup}
\bibcite{DBLP:journals/corr/abs-1207-0580}{1}
\bibcite{726791}{2}
\bibcite{ngsparseae}{3}
\bibcite{Tibshirani94regressionshrinkage}{4}
\bibstyle{acm}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A Neural Network with 5 hidden units trained on a single variable regression problem.}}{6}}
\newlabel{neuralregression}{{6}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of notation used for Neural Networks}}{7}}
